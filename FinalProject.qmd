---
title: "Shake It Off-ense: A Statitistical Study On Taylor Swifts Influence On The Kansas City Chiefs"
---

## Motivation and Context

Over the past 3 years I've become interested in fantasy football which has led me to explore statitics associated with football in order to better understand predicted out comes of performance of players and teams. Growing up with two sisters , I also grew up listening to alot of Taylor Swift.  I've also grown up with two sisters who have been die hard Taylor Swift fans their whole lives. Though these two facts about my life seem to be unrelated however, If you've watched a Kansis city chiefs game in the past two years or heard any news at all about Taylor Swift, you would know that they are unfortunately very related. The world was set ablaze in September 2023 when Taylor Swift and Travis Kelce announced they were in a relationship. Ticket and Travis Kelce Jersey revenue skyrocketed as the market was introduced to millions of Swifties trying to secure the latest Taylor Swift clout to wear at her next show. As their high profile relationship continues, I am interested in how this relationship has effected the perfomance of the Kansas City.

```{r}
#| label: do this first
#| echo: false
#| message: false

# change this to the location of your Quarto file containing your project; then delete this comment
here::i_am("FinalProject.qmd")
```

## Main Objective

How does Taylor Swift's attendance at Kansas City Chiefs games effect the offensive performance.

## Packages Used In This Analysis

```{r}
#| label: load packages
#| message: false
#| warning: false

library(splines)
library(tidyverse)
library(kknn)
library(Lahman)
library(probably)
library(knockoff)
library(selectiveInference)
library(tidymodels)
library(modeltime)
library(readr)
library(stringr)
library(ggplot2)  
library(dplyr)
```

| Package | Use |
|--------------------------------|----------------------------------------|
| [here](https://github.com/jennybc/here_here) | to easily load and save data |
| [readr](https://readr.tidyverse.org/) | to import the CSV file data |
| [dplyr](https://dplyr.tidyverse.org/) | to massage and summarize data |
| [rsample](https://rsample.tidymodels.org/) | to split data into training and test sets |
| [ggplot2](https://ggplot2.tidyverse.org/) | to create nice-looking and informative graphs |
| [tidyverse](https://www.tidyverse.org/) | a collection of R packages designed for data science |
| [kknn](https://cran.r-project.org/web/packages/kknn/index.html) | for k-nearest neighbors classification and regression |
| [Lahman](https://cran.r-project.org/web/packages/Lahman/index.html) | provides baseball statistics data for analysis |
| [probably](https://probably.tidymodels.org/) | to post-process and threshold model predictions |
| [knockoff](https://cran.r-project.org/web/packages/knockoff/index.html) | for feature selection with controlled false discovery rate |
| [selectiveInference](https://cran.r-project.org/web/packages/selectiveInference/index.html) | for valid statistical inference after model selection |
| [tidymodels](https://www.tidymodels.org/) | a unified framework for modeling and machine learning |
| [modeltime](https://business-science.github.io/modeltime/) | for time series forecasting using tidymodels workflow |
| [stringr](https://stringr.tidyverse.org/) | to manipulate and work with strings easily |

## Data Description

The data I will be using is Kansas City Chiefs season performance statistics form https://www.pro-football-reference.com/ from 2013 to 2024. This data is collected from the staff of Pro Football Reference. This site is the leading football statistical reference site, and is sited by many others. I am constricting data to 2013 - 2024 since 2013 is when Patrick Mahomes was drafted onto the Kansas City Chiefs ans started a new era of their franchise.

Variables

Year - Year game took place. 
Week - Week of the season game took place. 
Day - Day of the week game took place. 
Time - Time of day game took place. 
Outcome - Outcome of game. 
OT - Indicates overtime took place. 
Rec - Redord of team. 
Location - Indicates hom or away game. 
Ppp - Opponent team name. 
PtS - Points scored. 
PtA - Points Allowed. 
FirstD - First down count. 
TotYd - Total yards gained. 
PassY - Passing yards. 
RushY - Rushng yards. 
TO - Timeouts taken. 
FirstD_Alwd - Opponentfirst dow count. 
TotYd_Alwd - Opponent total yards gained.
PassY_Alwd - Opponent total passing yards. 
RushY_Alwd - Opponent total rushing yards. 
TO_Alwd - Opponent touchdowns 
ExOff - Expected Offensive performance. 
ExDef - Average expected points for every play. 
ExSpec - Expected special teams performance.
Taylor_Attend - Indicates attendance of Taylor Swift

```{r}
#| label: import data
#| warning: false
kcc_g_16 <- read_csv("C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data/kcc_g_16.txt", show_col_types = FALSE)
kcc_g_24 <- read_csv("C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data/kcc_g_24.txt", show_col_types = FALSE)
kcc_g_23 <- read_csv("C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data/kcc_g_23.txt", show_col_types = FALSE)
kcc_g_22 <- read_csv("C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data/kcc_g_22.txt", show_col_types = FALSE)
kcc_g_21 <- read_csv("C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data/kcc_g_21.txt", show_col_types = FALSE)
kcc_g_20 <- read_csv("C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data/kcc_g_20.txt", show_col_types = FALSE)
kcc_g_19 <- read_csv("C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data/kcc_g_19.txt", show_col_types = FALSE)
kcc_g_18 <- read_csv("C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data/kcc_g_18.txt", show_col_types = FALSE)
kcc_g_17 <- read_csv("C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data/kcc_g_17.txt", show_col_types = FALSE)
kcc_g_16 <- read_csv("C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data/kcc_g_16.txt", show_col_types = FALSE)
kcc_g_15 <- read_csv("C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data/kcc_g_15.txt", show_col_types = FALSE)
kcc_g_14 <- read_csv("C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data/kcc_g_14.txt", show_col_types = FALSE)
kcc_g_13 <- read_csv("C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data/kcc_g_13.txt", show_col_types = FALSE)
```

### Data Limitations

Choosing a variable to indicate the success of the offense is the first step. Variables such as Outcome, PtS (points scored), TotYd (total yards gained) all seem to be adequate indicators for success for an offence. It is significant that we are measuring strictly offensive performance. Therefore any variable also indicating Defensive performance or Special teams performance should be left out. Whn using Outcome as an indicator fo success, we'd be studying whether the Chiefs won or lost a game. In football , the defensive performance is largly viewed as more important than offensive performance iin securing a win. For this reason, whether a team won or loss is largly an indcator whether the defence performed well or not. For this reason we will not use Outcome as a response variable. TotYd (total yards gained) seems to be a good response variable because it shows how many yards the offense was able to gain during a game. This does not include yards gained by defense or special teams. It makes sense to explore yards gained by an offense to measure success, however the goal of an offense is not to merely gain yards, but to score points. This variable fails to reward offenses for scoring points. The advantage to using PtS (points scored) to measure for success is that it rewards offenses for yards gained and for scoring points. It also rewards offenses for field goals which indicates a mild success of an offense. However, this variable indicates total points gained by offense, defense and special teams. THis means that defenseive scores i.e. pick sixes, fumble recoveries for touchdowns and safeties, also contributre to this variable. Extra points also contribute to this data. This does points score less accurate when strickly measuring offensive performance, however these forms of scoring not associated with the offense are rare and will not effect our results significantly. The perfect variable we could use would be offensive points scored, however this variable does not exist, therefore we will settle with Points scored.

Another important factor when measuring offensive success is the skill of the opposing defense. Points scored against some teams are more impressive than other teams. 30 points scored against an inadequate defense may be less impressive that 14 points scored against the top defense in the league. To account for this, a variable could be constructed indicating the difference between predicted verse actual points scred by offene. THis variable would then indicate how well an offense performed against induvidual defenses. However, predicted points scored by offense is not a variable we have access to.

We will proceed to use PtS (points scored) as a response variable for the success of the Chiefs Offense. The drawbacks and inaccuracies that some with using this variable as a indicator for offensive success should be kept in mind when considering the acccuracy of our model.

## Data Wrangling

Some data wrangling for our data sets to be in a usable format. We will move the column and row names to appropriate positions in our data frame. We will also rmeove week title and substitue them, for week numbers. We will also add a Taylor Attendance variable from data produced by me.

```{r}
file_paths <- list.files(path = "C:/Users/caleb/OneDrive/Desktop/School/Math 437/Final Project/Project Data", 
                         pattern = "kcc_g_.*\\.txt$", full.names = TRUE)

new_col_names <- c("Week", "Day", "Date", "Time", "Boxscore", "Outcome", "OT", "Rec", 
                   "Location", "Ppp", "PtS", "PtA", "FirstD", "TotYd", "PassY", "RushY", 
                   "TO", "FirstD_Alwd", "TotYd_Alwd", "PassY_Alwd", "RushY_Alwd", 
                   "TO_Alwd", "ExOff", "ExDef", "ExSpec")

kcc_data <- lapply(file_paths, function(file) {
  df <- read_csv(file, skip = 1, show_col_types = FALSE)   # Read the file
  colnames(df) <- new_col_names  # Rename columns
  year_suffix <- str_extract(basename(file), "\\d{2}")
  full_year <- as.integer(paste0("20", year_suffix))  # Convert to 4-digit year

  df <- df |> filter(Week != "Playoffs") #Removes playoff row
  df <- df |> filter(Ppp != "Bye Week") #removes bie week row
  df <- df |> mutate(Taylor_Attend = "no") #Adds attendance collumn
  df <- df |>  mutate(Year = full_year) |>  # Add Year column
    
    relocate(Year, .before = Week)  # Move Year column before Week
  df <- df |> mutate(
    Date = paste(Date, full_year),  # Combine Date and Year
    Date = as.Date(Date, format = "% %d %Y")  # Convert to Date format (e.g., "September 13 2013")
  )

  df <- df |> mutate(
    Week = case_when(  # Replace playoff names with sequential week numbers
        Week == "Wild Card" ~ "18",
        Week == "Division" ~ "19",
        Week == "Conf. Champ." ~ "20",
        Week == "SuperBowl" ~ "21",
        TRUE ~ as.character(Week)  # Keep regular weeks unchanged
      )
  )
  return(df)  # Return the modified dataframe
})

names(kcc_data) <- gsub(".*/|\\.txt$", "", file_paths)  # Remove path and .txt extension

# Assign each dataframe to a separate variable
for (name in names(kcc_data)) {
  assign(name, kcc_data[[name]])
}

Taylor_Attend23 <- c("no", "no", "yes", "yes", "no", "yes", "yes", "no", "no", "no", "no", "yes", "yes", "yes", "yes", "yes", "no", "yes", "yes", "yes", "yes")
Taylor_Attend24 <- c("yes", "yes", "no", "no", "yes", "no", "no", "yes", "yes", "no", "no", "yes", "no", "no", "yes", "no", "no", "yes", "yes", "yes")

kcc_g_23 <- kcc_g_23 |> mutate(Taylor_Attend = Taylor_Attend23)
kcc_g_24 <- kcc_g_24 |> mutate(Taylor_Attend = Taylor_Attend24)
```

## Exploratory Data Analysis

For our EDA we will look the Chiefs performance during Travis Kelce and Taylor Swift's relationship. Ther relationship began in Septermber of 2023 with Taylporo attending her frst Chiefs game on September 24th, 2023. For this reason, we will look at the Chiefs 2023 and 2024 seasons to access our data.

When creating a training set for our data, we will go back to 2013. This was the year Andy Reid became the head coach of the Kansas City Chiefs and marks the beginning of a new era for the team. We are not using data from before 2013, as it would skew our model toward the performance of the Chiefs during a fundamentally different period — before Reid's leadership and the offensive system he brought with him. Including older data would dilute the model’s ability to learn patterns that reflect the team’s modern strategies, play style, and overall performance under Reid’s coaching.

```{r}
kcc_g_train <- bind_rows(list(kcc_g_13, kcc_g_14, kcc_g_15, kcc_g_16, kcc_g_17, kcc_g_18, kcc_g_19, kcc_g_20, kcc_g_21, kcc_g_22))
kcc_g_test <- bind_rows(kcc_g_23, kcc_g_24)
kcc_g_all <- bind_rows(kcc_g_train, kcc_g_test)
kcc_g_dyn <- bind_rows(kcc_g_19, kcc_g_20, kcc_g_21, kcc_g_22, kcc_g_23, kcc_g_24)
kcc_g_taylor <- filter(kcc_g_test, Taylor_Attend == "yes")
kcc_g_taylorless <- filter(kcc_g_test, Taylor_Attend == "no")
```

To give context as to how the Chiefs performed during his time period, here is the distribution of points scored for 2013 to 2024 seasons.

```{r}
ggplot(kcc_g_all, aes(x = as.factor(Year), y = PtS, fill = as.factor(Year))) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Points Scored Per Game Distribution by Year",
       x = "Year", 
       y = "Points Scored Per Game (PtS)")
```

A notable increase in points scored can be observed from 2017 to 2018. This was the year that Patrick Mahomes became the starting quarterback. It may be necessary to constrict our training data to 2018 - 2024 data, however this would lead to far less data to train our model with (only 4 seasons of data!). Therefore we will proceed with or initial 2013 to 2024 seasons.

We will now explore the distribution of Points scored by the Chiefs when Taylor Attended verses games she did not attend.

```{r}
kcc_g_test |> group_by(Taylor_Attend) |> 
  summarize(
    num_total = n(),
    num_missing = sum(is.na(PtS)),
    min = min(PtS, na.rm = TRUE),
    Q1 = quantile(PtS, 0.25, na.rm = TRUE),
    median = median(PtS, na.rm = TRUE),
    Q3 = quantile(PtS, 0.75, na.rm = TRUE),
    max = max(PtS, na.rm = TRUE),
    mean = mean(PtS, na.rm = TRUE),
    sd = sd(PtS, na.rm = TRUE)
  )
ggplot(data = kcc_g_test, aes(x = Taylor_Attend, y = PtS, fill = Taylor_Attend)) + 
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.5) +  # Avoids overlapping points
  coord_flip() +
  theme_minimal() +
  labs(title = "Boxplot of PtS during 2023 - 2024",
       x = "Taylor Attend",
       y = "PtS") +
  scale_fill_manual(values = c( "no" = "red", "yes" = "blue"), labels = c("Games Taylor Did Not Attend", "Games Taylor Attended"))
```

As you can see, the games which Taylor attended seem to have a greater distribution than the games she did not attend with about a 4 point greater mean. We will also note that the two highest scoring games occurred when Taylor was attending and the two lowest scoring games occurred when she was not attending.

We will proceed to observe the relationship our variables have with Points Scored.

The following is a plot of Total Yards and Points Scored, with blue and red data points indicating Taylor's attendance and non-attendance, respectively.

```{r plottig TotYd and PtS}
ggplot(kcc_g_test, aes(x = TotYd, y = PtS, color = Taylor_Attend)) +
  geom_point(size = 4, alpha = 0.8) +
  scale_color_manual(values = c("red", "blue")) +
  labs(
    title = "Chiefs Points Scored vs Total Yards",
    x = "Total Yards (TotYd)",
    y = "Points Scored (PtS)",
    color = "Taylor Swift Attendance"
  ) +
  theme_minimal()

```

Unsurprisingly, we can observe a fairly linear relationship here.

Next we will observe the relationship between ExOff and PtS variables. Unfortunately, I am unaware as to what ExOff is predicting. It is an indication of some sorts of the offensive performance of the team. I am hypothesizing that it is the average expected score for each offensive play of the game.

```{r plottig ExOff and PtS}
ggplot(kcc_g_test, aes(x = ExOff, y = PtS, color = Taylor_Attend)) +
  geom_point(size = 4, alpha = 0.8) +
  scale_color_manual(values = c("red", "blue")) +
  labs(
    title = "Chiefs ExOff vs Total Yards",
    x = "Total Yards (TotYd)",
    y = "Points Scored (PtS)",
    color = "Taylor Swift Attendance"
  ) +
  theme_minimal()

```

A linear relationship is again observable; however, we have chosen not to include this variable in our model, as its underlying significance is unclear.

Lastly, we will observe the relationship between fist down count and Points scored.

```{r plottig FirstD and PtS}
library(ggplot2)

ggplot(kcc_g_test, aes(x = FirstD, y = PtS, color = Taylor_Attend)) +
  geom_point(size = 4, alpha = 0.8) +
  scale_color_manual(values = c("red", "blue")) +
  labs(
    title = "Chiefs First Down Count vs Total Yards",
    x = "Total Yards (TotYd)",
    y = "Points Scored (PtS)",
    color = "Taylor Swift Attendance"
  ) +
  theme_minimal()

```

We will now find appropriate explanatory variables with a LASSO model

```{r Lasso-tidy model}
kcc_lasso_model <- linear_reg(mode = "regression", engine = "glmnet",
                          penalty = tune(), 
                          mixture = 1) 

kcc_lasso_recipe <- recipe(
  PtS ~ PtA 
  + FirstD 
  + TotYd 
  + PassY 
  + RushY 
  + TotYd_Alwd 
  + PassY_Alwd 
  + RushY_Alwd, 
  data = kcc_g_train
) |>
  step_normalize(all_numeric_predictors()) |> 
  step_dummy(all_nominal_predictors())

kcc_lasso_wflow <- workflow() |>
  add_model(kcc_lasso_model) |>
  add_recipe(kcc_lasso_recipe) 
```

```{r tune model kfold lasso}
kcc_cv <- vfold_cv(kcc_g_train, v = 10)
kcc_lasso_tune <- tune_grid(kcc_lasso_model, 
                      kcc_lasso_recipe, 
                      resamples = kcc_cv, 
                      grid = grid_regular(penalty(range = c(-2, 2)), levels = 50))
```

```{r}
kcc_lasso_tune |>
  collect_metrics() |>
  filter(.metric == "rmse") |>
  ggplot(mapping = aes(x = penalty, y = mean)) + geom_point() + geom_line() +
  scale_x_log10()
```

```{r select best lasso}
lasso_best <- kcc_lasso_tune |>
  select_best(
    metric = "rmse"
)
lasso_best
```

We will do a calibration check to see how our penalized variable do in predicting our model.

```{r lasso calibration check}
library(modeltime)
library(ggplot2)
lasso_wflow_final <- kcc_lasso_wflow |>
  finalize_workflow(parameters = lasso_best) 

lasso_pred_check <- lasso_wflow_final |>
  fit_resamples(
    resamples = kcc_cv,
    # save the cross-validated predictions
    control = control_resamples(save_pred = TRUE)
) |> 
  collect_predictions()

# using built-in defaults from probably
cal_plot_regression(
  lasso_pred_check,
  truth = PtS,
  estimate = .pred
)
```

The Lasso model does mildly well in predicting values.

```{r fit lasso-tidy model}
kcc_lasso_fit <- lasso_wflow_final |>
  fit(data = kcc_g_train)
kcc_lasso_fit
```

```{r look at lasso path}
kcc_lasso_fit |>
  extract_fit_engine() |>
  plot(xvar = "lambda", label = TRUE)
```

```{r get coefficient estimates lasso}
kcc_lasso_coef <- kcc_lasso_fit |>
  broom::tidy()
kcc_lasso_coef 
```

Here we can see that important variables are, First Down Count, Total Yards, Rushing Yards, and Passing Yards Allowed. We will now train a model with this data.

## Modeling

### Model Selection

We will start by choosing an appropriate model. The models we will be considering are: Linear Regression, Polynomial Regression, K-Nearest Neighbors, and Spline Regression (Natural Splines). We will compare RMSE or Root Mean Squared Errors of these models to determine which model fits our data best. Root Mean Squared Error is defined as:

$$
\text{RMSE} = \sqrt{ \frac{1}{n} \sum_{i=1}^{n} \left( \hat{y}_i - y_i \right)^2 }
$$

RMSE measures how off a given model is by finding the average squared difference between predicted values and actual values. We then take the square root of this value to account for the square that occurred in the residual terms. A higher value RMSE indicates on average, a higher amount of inaccuracy in a model. Therefore, we will be looking for the model with the lowest RSME.

In order to determine the RMSE of these models, we will use 10-fold Cross Validation (10-fold CV). The process of 10-fold CV involves splitting our training datainto 10 equal parts or "folds". We then take these folds in tur and hold them out as test sets. We train our moel on te remaining 9 folds, then test our model on the remaining heldout test fold, and find the RMSE. After repeating this process with the 9 other folds we will have 10 RMSE values tat we will take the averae of. We will do thiisfor each model then determine whic model produces the smallest RMSE.

```{r defining models}
kcc_linreg_model <- linear_reg(mode = "regression", engine = "lm")
kcc_knn_model <- nearest_neighbor(mode = "regression",
                              engine = "kknn",
                              neighbors = tune(), dist_power = 2)
```

```{r defining model recipes}
kcc_linear_recipe <- recipe(
  PtS ~ FirstD
  + TotYd 
  + RushY 
  + PassY_Alwd, 
  data = kcc_g_train
)

kcc_quadratic_recipe <- recipe(
  PtS ~ FirstD
  + TotYd 
  + RushY 
  + PassY_Alwd,
  data = kcc_g_train
) |>
  step_poly(TotYd, degree = 2)

kcc_knn_recipe <- recipe(
  PtS ~ FirstD
  + TotYd 
  + RushY 
  + PassY_Alwd,
  data = kcc_g_train
) |>
  step_normalize(all_numeric_predictors())

kcc_ns_recipe <- recipe( PtS ~ FirstD
  + TotYd 
  + RushY 
  + PassY_Alwd,
  data = kcc_g_train) |> step_ns(TotYd, deg_free = 4)
```

```{r create workflow set}
all_models <- workflow_set(
  preproc = list(linear = kcc_linear_recipe, quadratic = kcc_quadratic_recipe, knn = kcc_knn_recipe, kcc_ns_recipe),
  models = list(lr = kcc_linreg_model,lr = kcc_linreg_model, knn = kcc_knn_model, lr = kcc_linreg_model),
  cross = FALSE # don't mix knn recipes with linear models or vice-versa
)
all_models
```

```{r Creating 10 folds out of trainig data}
# 10-fold cv, not repeated
set.seed(1112)
kcc_cv <- vfold_cv(kcc_g_train, v = 10)
```

```{r tuning knn model and producing RMSE values}
knn.grid <- expand.grid(neighbors = seq(2,16, by = 2)) # set up tuning grid

all_models <- workflow_set(
  preproc = list(linear = kcc_linear_recipe,
                 quadratic = kcc_quadratic_recipe,
                 knn = kcc_knn_recipe,
                 ns = kcc_ns_recipe
                 ),
  models = list(lr = kcc_linreg_model,
                lr = kcc_linreg_model,
                knn2 = kcc_knn_model,
                lr = kcc_linreg_model), # this is what is being tuned
  cross = FALSE 
)

all_models <- all_models |>
  # add the grid for JUST the knn model
  option_add(grid = knn.grid, id = "knn_knn2") |> #adding grid
  workflow_map("tune_grid",
               resamples = kcc_cv,
               metrics = metric_set(rmse), # can add more
               verbose = TRUE)

all_models
```

We will now plot the RMSE values to compare values.

```{r plot stuff with autoplot}
autoplot(all_models)
```

The 3 red RMSE values are the linear, quadratic and spline regression models. The blue RMSE values are the K-Nearest Neighbor values with different K-values. As you can see the linear, quadratic and spline regression models preform better than the K-nearest Neighbors model. We will now determine the RMSE values of our linear, quadratic and spline regression models.

```{r rank results}
rank_results(all_models) |>
  dplyr::select(wflow_id, .config, .metric, mean, std_err, rank) |>
  arrange(.metric, rank)
```

The quadratic model performed best with an RMSE of 7.77. We will proceed to use this to model our training set.

# Train Model

As noted before, we will be using 2013 to 2022 seasons to train our quadratic regression model. These seasons are included in the kcc_g_train data frame. We will be using the variables our LASSO model selected: FirstD (first down count), TotYd (Total Yards), RushY (rushing yards), and PassY_Alwd (Passing yards allowed).

```{r workflow linear}
kcc_linear_model <- linear_reg(mode = "regression", engine = "lm")

kcc_linear_wflow <- workflow() |>
  add_model(kcc_linear_model)
```

```{r create recipe linear}
kcc_quadratic_recipe <- recipe(
  PtS ~ FirstD
  + TotYd 
  + RushY 
  + PassY_Alwd,
  data = kcc_g_train
) |>
  step_poly(TotYd, degree = 2)
```

```{r add recipe to workflow linear}
kcc_quadratic_wflow <- kcc_linear_wflow |>
  add_recipe(kcc_quadratic_recipe)


kcc_quadratic_wflow
```

```{r fit linear model}
kcc_quadratic_fit <- fit(kcc_quadratic_wflow, data = kcc_g_train)
kcc_quadratic_fit
```

Now that we have trained our model on 2013 to 2022 seasons, we now will predict the outcome of 2023 and 2024 points scored based on our chosen data, in hopes to observe a difference in residuals between games at which Taylor Attended veseres the games she did not attend.

# Predict response

As stated before , we will now predict the Points scored of games that occurred during Taylor Swift and Travis Kelce's relationship, which are 2023 and 2024 seasons.

The following are the predictions of the test data with both Taylor games (games which Taylor Swift attended) and Taylorless games (games which Taylor Swift did no attend).

```{r augmenasdfat linear regression}
# augment is in the broom package, loaded with tidymodels
kcc_predictions_test <- kcc_quadratic_fit |>
  augment(
  new_data = kcc_g_test,
)
  
kcc_predictions_test |>
  dplyr::select(
    Year,
    Ppp,
    PtS,
    .pred
  )

```

Now we will predict the points scored over our Taylor Games

```{r}
# augment is in the broom package, loaded with tidymodels
kcc_predictions_taylor <- kcc_quadratic_fit |>
  augment(
  new_data = kcc_g_taylor,
)
  
kcc_predictions_taylor |>
  dplyr::select(
    Year,
    Ppp,
    PtS,
    .pred,
    PtA,
    TotYd,
    PassY,
    RushY,
    TotYd_Alwd,
    PassY_Alwd,
    RushY_Alwd,
    everything()
  )

```

Here is a graph of the residuals verses fit and the rsme value.

```{r}
kcc_predictions_taylor |>
  mutate(
    residual = PtS - .pred
  ) |>
  ggplot(
    mapping = aes(x = .pred, y = residual)
  ) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  theme_minimal() +
  labs(title = "Residuals vs. Fitted Values of Test Set")

rmse(kcc_predictions_taylor,
     truth = PtS,
     estimate = .pred)
```

There is no clear pattern in our residual vs fitted graph, indicating our model is capturing our data correctly. We also have an rmse of 5.31 indicating on average, our model has an error of 5.56 points.

Next we will predict the points scored of Taylorless games.

```{r}
# augment is in the broom package, loaded with tidymodels
kcc_predictions_taylorless <- kcc_quadratic_fit |>
  augment(
  new_data = kcc_g_taylorless,
)
  
kcc_predictions_taylorless |>
  dplyr::select(
    Year,
    Ppp,
    PtS,
    .pred,
    PtA,
    TotYd,
    PassY,
    RushY,
    TotYd_Alwd,
    PassY_Alwd,
    RushY_Alwd,
    everything()
  )

```

Here is a graph of the residuals verses fit and the rsme value of Taylorless games.

```{r}
kcc_predictions_taylorless |>
  mutate(
    residual = PtS - .pred
  ) |>
  ggplot(
    mapping = aes(x = .pred, y = residual)
  ) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  theme_minimal() +
  labs(title = "Residuals vs. Fitted Values of Test Set")
rmse(kcc_predictions_taylorless,
     truth = PtS,
     estimate = .pred)
```

Similar as before, there is no clear pattern in our residual vs fitted graph, indicating our model is capturing our data correctly. We also have an rmse of 6.76 indicating on average, our model has an error of 6.76.

The rsme is good to assess how well our model did in modeling absolute distance but we want to know whether the points scored was above or below our prediction, indicating a better or worse performance. We will calculate the Bias to determine this. Bias refers to the error that is introduced by approximating a real life problem. The main difference between Bias and Root Mean Square Error or Mean Squared Error is that the residuals (difference between predicted values and actual values) are not squared, therefore direction of the error is preserved.

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} \left( \hat{y}_i - y_i \right)^2
$$

$$
\text{RMSE} = \sqrt{ \frac{1}{n} \sum_{i=1}^{n} \left( \hat{y}_i - y_i \right)^2 }
$$

$$
\text{Bias} = \frac{1}{n} \sum_{i=1}^{n} \left( \hat{y}_i - y_i \right)
$$

```{r}
Taylor_Bias <- -kcc_predictions_taylor$.resid |> mean()
Taylor_Bias 
Taylorless_Bias <- -kcc_predictions_taylorless$.resid |> mean()
Taylorless_Bias
```

As seen above, the bias for our Taylor mode is 1.47 while the bias for our Taylorless model is 2.97.

## Insights

Our Taylor-attended model has a bias of 1.47, while the Taylor-less model has a bias of 2.97 with a difference of 1.500. Bias is calculated from the perspective of the model, meaning that a positive bias indicates the model is over predicting, while a negative bias would indicate under prediction. Smaller absolute values of bias suggest a better model fit. The larger positive bias in the Taylor-less model suggests that the model over predicted more frequently when Taylor Swift did not attend games.

Since both models have positive bias values, this implies that the Chiefs tended to under perform in both scenarios. However, the higher bias in games without Taylor’s attendance indicates a greater average under performance in those games, relative to what the model predicted. This is an indication that the Chiefs tend to perform slightly better when Taylor Swift is present at their games.

The average points score of Chiefs games from 2013 to 2024 is 26.85. This would mean that if Taylor's attendance would theoretically have a 5.58% increase in score. This is a fairly significant advantage when observing Points scored as an indicator of offensive success. However, between 2013 and 2024, there are only 10 games where the Chiefs lost by 2 points or fewer—scenarios where a 1.5-point scoring advantage could conceivably have changed the outcome of the game.

### Limitations and Future Work

### Reflection (Optional Subsection)
